---
title: 「CourseNote」wangshusen Transformer
author: Hadrian X
date: 2025-08-14 16:30:00 +0800
categories:
  - CourseNote
  - Basics
tags:
  - wangshusen
  - transformer
pin: false
math: true
mermaid: false
---

## Transformer Model (1/2)
![image.png](https://cdn.jsdelivr.net/gh/hadrian0612/image/images/20250814163342012.png)
- Transformer is a Seq2Seq model with encoder-decoder architecture
- Purely based attention and dense layers

## Transformer Model (2/2)

## Appendix
- [Attention_Is_All_You_Need](https://arxiv.org/pdf/1706.03762)
